{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Image-Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quickstart Guide\n",
        "\n",
        "This guide will give a quick intro to training PyTorch models with HugsVision. We'll start by loading in some data and defining a model, then we'll train it for a few epochs and see how well it does.\n",
        "\n",
        "**Note**: The easiest way to use this tutorial is as a colab notebook, which allows you to dive in with no setup. We recommend you enable a free GPU with\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n",
        "\n",
        "**Note**: You need to have at least Python 3.6 to run the scripts.\n",
        "\n",
        "## Install HugsVision\n",
        "\n",
        "First we install HugsVision if needed. "
      ],
      "metadata": {
        "id": "Pzd_l-d4IBap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "try:\r\n",
        "    import hugsvision\r\n",
        "except:\r\n",
        "    !pip install -q hugsvision\r\n",
        "    import hugsvision\r\n",
        "    \r\n",
        "print(hugsvision.__version__)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZYAyYoSkISKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Data\r\n",
        "\r\n",
        "First, we need to download the dataset called `Kvasir Dataset v2` [here](https://datasets.simula.no/kvasir/) which weight around ~2.3 GB."
      ],
      "metadata": {
        "id": "tht3p78fIav4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data\n",
        "\n",
        "Once it has been converted, we can start loading the data."
      ],
      "metadata": {
        "id": "1n_kAX_gJ10T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from hugsvision.dataio.VisionDataset import VisionDataset\r\n",
        "\r\n",
        "train, test, id2label, label2id = VisionDataset.fromImageFolder(\r\n",
        "\t\"./data/\",\r\n",
        "\ttest_ratio   = 0.15,\r\n",
        "\tbalanced     = True,\r\n",
        "\taugmentation = True,\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "3VAjDhVsKSkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose a image classifier model on HuggingFace\n",
        "\n",
        "Now we can choose our base model on which we will perform a fine-tuning to make it fit our needs.\n",
        "\n",
        "Our choices aren't very large since we haven't a lot of model available yet on HuggingFace for this task.\n",
        "\n",
        "So, to be sure that the model will be compatible with `HugsVision` we need to have a model exported in `PyTorch` and compatible with the `image-classification` task obviously.\n",
        "\n",
        "Models available with this criterias: https://huggingface.co/models?filter=pytorch&pipeline_tag=image-classification&sort=downloads\n",
        "\n",
        "At the time I'am writing this, I recommand to use the following models:\n",
        "\n",
        "*   `google/vit-base-patch16-224`\n",
        "*   `facebook/deit-base-distilled-patch16-224`\n",
        "*   `microsoft/beit-base-patch16-224`"
      ],
      "metadata": {
        "id": "2cKwvSqdKeQf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "huggingface_model = 'facebook/deit-base-distilled-patch16-224'"
      ],
      "outputs": [],
      "metadata": {
        "id": "TYpe3zYHNWpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "So, once the model choosen, we can start building the `Trainer` and start the fine-tuning:"
      ],
      "metadata": {
        "id": "bI1MYIzgNcL5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "from hugsvision.nnet.VisionClassifierTrainer import VisionClassifierTrainer\r\n",
        "from transformers import DeiTFeatureExtractor, DeiTForImageClassification\r\n",
        "\r\n",
        "trainer = VisionClassifierTrainer(\r\n",
        "\tmodel_name   = args.name,\r\n",
        "\ttrain      \t = train,\r\n",
        "\ttest      \t = test,\r\n",
        "\toutput_dir   = args.output,\r\n",
        "\tmax_epochs   = args.epochs,\r\n",
        "\tbatch_size   = 32, # On RTX 2080 Ti\r\n",
        "\ttest_ratio   = 0.15,\r\n",
        "    lr \t\t     = 2e-5,\r\n",
        "\tfp16\t     = True,\r\n",
        "\tbalanced     = True,\r\n",
        "\taugmentation = True,\r\n",
        "\tmodel = DeiTForImageClassification.from_pretrained(\r\n",
        "\t    huggingface_model,\r\n",
        "\t    num_labels = len(label2id),\r\n",
        "\t    label2id   = label2id,\r\n",
        "\t    id2label   = id2label\r\n",
        "\t),\r\n",
        "\tfeature_extractor = DeiTFeatureExtractor.from_pretrained(\r\n",
        "\t\thuggingface_model,\r\n",
        "\t),\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "60F0IXvQNc0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate F1-Score\n",
        "\n",
        "Using the F1-Score metrics will allow us to get a better representation of predictions for all the labels and find out if their are any anomalies wit ha specific label."
      ],
      "metadata": {
        "id": "C56x7mkEN6Rx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hyp, ref = trainer.evaluate_f1_score()"
      ],
      "outputs": [],
      "metadata": {
        "id": "hC2pA2EzQahn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\r\n",
        "                        precision    recall  f1-score   support\r\n",
        "\r\n",
        "    dyed-lifted-polyps       0.93      0.94      0.93       145\r\n",
        "dyed-resection-margins       0.95      0.95      0.95       169\r\n",
        "           esophagitis       0.86      0.86      0.86       126\r\n",
        "          normal-cecum       0.99      0.99      0.99       144\r\n",
        "        normal-pylorus       1.00      0.98      0.99       172\r\n",
        "         normal-z-line       0.87      0.88      0.88       140\r\n",
        "                polyps       0.98      0.99      0.98       146\r\n",
        "    ulcerative-colitis       0.97      0.97      0.97       158\r\n",
        "\r\n",
        "              accuracy                           0.95      1200\r\n",
        "             macro avg       0.94      0.94      0.94      1200\r\n",
        "          weighted avg       0.95      0.95      0.95      1200\r\n",
        "```"
      ],
      "metadata": {
        "id": "qPCJviqYQdb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a prediction\r\n",
        "\r\n",
        "Rename the `./out/MODEL_PATH/config.json` file present in the model output to `./out/MODEL_PATH/preprocessor_config.json`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os.path\r\n",
        "from transformers import DeiTFeatureExtractor, DeiTForImageClassification\r\n",
        "from hugsvision.inference.VisionClassifierInference import VisionClassifierInference\r\n",
        "\r\n",
        "path = \"./out/KVASIR_V2_MODEL_DEIT/20_2021-08-20-01-46-44/model/\"\r\n",
        "img  = \"../../../samples/kvasir_v2/dyed-lifted-polyps.jpg\"\r\n",
        "\r\n",
        "classifier = VisionClassifierInference(\r\n",
        "    feature_extractor = DeiTFeatureExtractor.from_pretrained(path),\r\n",
        "    model = DeiTForImageClassification.from_pretrained(path),\r\n",
        ")\r\n",
        "\r\n",
        "label = classifier.predict(img_path=img)\r\n",
        "print(\"Predicted class:\", label)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}